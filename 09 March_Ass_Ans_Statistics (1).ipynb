{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "# an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaae3ba",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are both mathematical functions that describe the probability distribution of a random variable.\n",
    "\n",
    ">The PMF is used to describe the probability distribution of a discrete random variable. It gives the probability that a discrete random variable takes on a certain value. Mathematically, the PMF is defined as:\n",
    "\n",
    "P(X = x) = f(x)\n",
    "\n",
    "Where P(X = x) is the probability that the random variable X takes on the value x, and f(x) is the PMF.\n",
    "\n",
    "For example, consider a fair six-sided die. The PMF for this die can be defined as:\n",
    "\n",
    "f(x) = 1/6, for x = 1, 2, 3, 4, 5, 6.\n",
    "\n",
    "This means that the probability of rolling any one of the six sides of the die is 1/6.\n",
    "\n",
    ">The PDF, on the other hand, is used to describe the probability distribution of a continuous random variable. It gives the probability density at a certain point in the continuous random variable’s range. Mathematically, the PDF is defined as:\n",
    "\n",
    "f(x) = dF(x)/dx\n",
    "\n",
    "Where f(x) is the PDF, F(x) is the cumulative distribution function, and dF(x)/dx is the derivative of the cumulative distribution function\n",
    "\n",
    "One example of a PDF is the Normal distribution, which is a widely used continuous probability distribution. The Normal distribution is often used to model real-world phenomena, such as the distribution of heights or weights of a population, or the distribution of errors in a measurement.\n",
    "\n",
    "For example, consider the normal distribution with mean μ = 0 and standard deviation σ = 1. The PDF for this distribution can be defined as:\n",
    "\n",
    "f(x) = (1/(σ * sqrt(2π))) * exp(-((x-μ)^2)/(2σ^2))\n",
    "\n",
    "This means that the PDF gives the probability density at any point x in the range of the normal distribution. The value of the PDF at any point x does not represent the probability of that specific value occurring, but rather represents the relative likelihood of values in that neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2421779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75305bdf",
   "metadata": {},
   "source": [
    ">The Cumulative Distribution Function (CDF) is a function used to describe the probability distribution of a random variable, whether it is discrete or continuous. The CDF gives the probability that the random variable takes on a value less than or equal to a specified value. Mathematically, the CDF is defined as:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "Where F(x) is the CDF and X is the random variable.\n",
    "\n",
    ">For example, consider the PMF for a fair six-sided die:\n",
    "\n",
    "f(x) = 1/6, for x = 1, 2, 3, 4, 5, 6.\n",
    "\n",
    "The CDF for this PMF can be defined as:\n",
    "\n",
    "F(x) = P(X ≤ x) = ∑f(i), for i = 1 to x\n",
    "\n",
    "This means that the CDF gives the probability that the die roll is less than or equal to a specified value of x. For example, the CDF for x = 3 is:\n",
    "\n",
    "F(3) = P(X ≤ 3) = f(1) + f(2) + f(3) = 1/6 + 1/6 + 1/6 = 1/2\n",
    "\n",
    "This means that the probability of rolling a value less than or equal to 3 on the die is 1/2.\n",
    "\n",
    ">The CDF is used because it provides a complete description of the probability distribution of a random variable. It can be used to calculate the probability of the random variable taking on a range of values, or to calculate percentiles of the distribution. The CDF is also used to generate random samples from the distribution, which is useful in simulations and statistical modeling. Overall, the CDF is a powerful tool for understanding and analyzing probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d780ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "# Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846f078",
   "metadata": {},
   "source": [
    "There are many real-world situations where the Normal distribution can be used as a model for a continuous variable. Some examples include:\n",
    "\n",
    "* Heights and weights of a population\n",
    "* IQ scores\n",
    "* Exam scores\n",
    "* Blood pressure readings\n",
    "* Reaction times\n",
    "\n",
    "The Normal distribution is a commonly used distribution because it has several useful properties, including:\n",
    "\n",
    "* Symmetry around the mean\n",
    "* Bell-shaped curve\n",
    "* A known mathematical form that can be easily integrated and manipulated\n",
    "* The mean and standard deviation uniquely determine the shape of the distribution\n",
    "\n",
    "The mean μ determines the location of the center of the distribution, while the standard deviation σ determines the spread or width of the distribution. Specifically, the shape of the Normal distribution is affected by the value of σ relative to the distance between the mean and the tails of the distribution.\n",
    "\n",
    "If σ is small relative to the distance between the mean and the tails, the distribution is narrow and tall, with most of the data clustered around the mean. On the other hand, if σ is large relative to the distance between the mean and the tails, the distribution is wide and short, with data spread out over a larger range of values.\n",
    "\n",
    "For example, consider two Normal distributions with the same mean of 50, but different standard deviations of 5 and 15. The distribution with the smaller standard deviation is narrow and tall, while the distribution with the larger standard deviation is wide and short. \n",
    "\n",
    "\n",
    "Therefore, the parameters of the Normal distribution have a direct relationship with the shape of the distribution, and understanding this relationship can be useful for modeling and interpreting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "# Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ee8a0",
   "metadata": {},
   "source": [
    "The Normal distribution is an important concept in statistics and probability theory due to its many useful properties. Here are some reasons why the Normal distribution is important:\n",
    "\n",
    "1. It is widely applicable: The Normal distribution is a versatile distribution that can be used to model many real-world phenomena, from the heights and weights of a population to the errors in a measurement. It is often used as a benchmark distribution for comparing other distributions.\n",
    "\n",
    "\n",
    "2. It is mathematically tractable: The Normal distribution has a well-defined mathematical form that can be easily integrated and manipulated, which makes it a useful tool for many statistical analyses.\n",
    "\n",
    "\n",
    "3. It has a central role in statistical inference: Many statistical methods rely on the assumption of Normality, such as hypothesis testing, confidence intervals, and linear regression.\n",
    "\n",
    "\n",
    "4. It has practical applications: The Normal distribution is used in a wide range of fields, from finance and engineering to psychology and biology. It is used to model data and make predictions, such as predicting the likelihood of a stock price moving in a certain direction or the likelihood of a patient responding to a certain treatment.\n",
    "\n",
    "Here are some real-life examples of Normal distribution:\n",
    "\n",
    "1. Heights of people in a population: The heights of a population tend to follow a Normal distribution, with a mean height around 5'7\" for men and 5'3\" for women, and a standard deviation of about 3 inches.\n",
    "\n",
    "\n",
    "2. IQ scores: IQ scores are standardized scores that follow a Normal distribution, with a mean of 100 and a standard deviation of 15.\n",
    "\n",
    "\n",
    "3. Test scores: Scores on standardized tests, such as the SAT or ACT, tend to follow a Normal distribution, with a mean around 500-600 and a standard deviation around 100-200.\n",
    "\n",
    "\n",
    "4. Reaction times: Reaction times in tasks such as pressing a button in response to a stimulus tend to follow a Normal distribution, with a mean around 200-300 milliseconds and a standard deviation around 50-100 milliseconds.\n",
    "\n",
    "\n",
    "5. Blood pressure readings: Blood pressure readings in a population tend to follow a Normal distribution, with a mean around 120/80 mmHg and a standard deviation of about 10 mmHg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e6d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "# Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2333b182",
   "metadata": {},
   "source": [
    "> The Bernoulli distribution is a discrete probability distribution that models the outcomes of a single binary experiment, where the outcome can be either success or failure. It is named after Swiss mathematician Jacob Bernoulli, who introduced it in his book Ars Conjectandi in 1713.\n",
    "\n",
    "The Bernoulli distribution has a probability of p for success and a probability of 1-p for failure, where 0 ≤ p ≤ 1. The distribution is denoted by Bern(p) and has a probability mass function (PMF) given by:\n",
    "\n",
    "P(X=1) = p\n",
    "P(X=0) = 1-p\n",
    "\n",
    "where X is the random variable that represents the outcome of the experiment.\n",
    "\n",
    ">An example of Bernoulli distribution is the outcome of a coin flip, where the outcome can be either heads or tails. If we define success as getting heads, then the probability of success (p) is 0.5, and the probability of failure (1-p) is also 0.5.\n",
    "\n",
    "The binomial distribution, on the other hand, models the number of successes in a fixed number of independent Bernoulli trials. It is a discrete probability distribution that is denoted by Bin(n,p), where n is the number of trials and p is the probability of success for each trial.\n",
    "\n",
    ">The main difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution models the outcome of a single binary experiment, while the binomial distribution models the number of successes in a fixed number of independent binary experiments. The Bernoulli distribution is a special case of the binomial distribution where n = 1.\n",
    "\n",
    "In summary, the Bernoulli distribution is a probability distribution that models the outcome of a single binary experiment, while the binomial distribution models the number of successes in a fixed number of independent binary experiments. The Bernoulli distribution is a special case of the binomial distribution where the number of trials is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e1cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "# is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "# than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71a61c6",
   "metadata": {},
   "source": [
    "To find the probability that a randomly selected observation will be greater than 60, we need to use the Normal distribution formula and standardize the value of 60 using the mean and standard deviation of the dataset.\n",
    "\n",
    "The formula for the Normal distribution is:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "where:\n",
    "Z = the standardized score\n",
    "\n",
    "X = the value of interest (in this case, 60)\n",
    "\n",
    "μ = the mean of the dataset (50)\n",
    "\n",
    "σ = the standard deviation of the dataset (10)\n",
    "\n",
    "Substituting the values, we get:\n",
    "\n",
    "Z = (60 - 50) / 10 = 1\n",
    "\n",
    "We can now use a standard Normal distribution table or calculator to find the probability that Z is greater than 1. Using a standard Normal distribution table, we find that the probability of Z being greater than 1 is approximately 0.1587.\n",
    "\n",
    ">Therefore, the probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf07c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c899bacd",
   "metadata": {},
   "source": [
    "The uniform distribution is a continuous probability distribution that models the probability of a random variable taking on any value within a specific interval, with each value having an equal probability of occurring.\n",
    "\n",
    "The probability density function (PDF) of a uniform distribution on the interval [a,b] is given by:\n",
    "\n",
    ">f(x) = 1/(b-a) for a <= x <= b\n",
    "\n",
    ">f(x) = 0 otherwise\n",
    "\n",
    "This means that the probability of a random variable taking on any value within the interval [a,b] is uniform, or constant, and equal to 1/(b-a).\n",
    "\n",
    "An example of the uniform distribution would be rolling a fair die, where the possible outcomes are the numbers 1 through 6, each with equal probability. The probability of each outcome is 1/6, which is constant and equal across all outcomes. Another example could be the arrival times of buses at a bus stop, where the buses arrive randomly between 10:00 am and 11:00 am, and each arrival time within this interval is equally likely.\n",
    "\n",
    "In summary, the uniform distribution is useful in situations where all outcomes within an interval have an equal chance of occurring, and the probability of each outcome is constant and uniform across the entire interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb4a8d4",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a statistical measure that indicates how many standard deviations a data point is from the mean of a distribution. It is calculated as the difference between a given observation and the population mean, divided by the population standard deviation.\n",
    "The formula for calculating the z-score of a data point x is:\n",
    "<b>z = (x - μ) / σ</b>\n",
    "where μ is the population mean, σ is the population standard deviation, and x is the value of the data point.\n",
    "\n",
    ">The z-score is important in statistics for several reasons:\n",
    "\n",
    "1. Standardization: The z-score standardizes data, allowing for comparisons between different data sets that have different units or scales.\n",
    "\n",
    "\n",
    "2. Normal distribution: The z-score is particularly useful in assessing the normality of a distribution. In a normal distribution, approximately 68% of the data falls within one standard deviation of the mean, and 95% falls within two standard deviations.\n",
    "\n",
    "\n",
    "3. Outlier detection: The z-score can be used to identify outliers, which are data points that are significantly different from the rest of the data. Typically, data points with a z-score greater than 3 or less than -3 are considered outliers.\n",
    "\n",
    "\n",
    "4. Hypothesis testing: The z-score is used in hypothesis testing to determine the probability of observing a particular result given a certain hypothesis.\n",
    "\n",
    "Overall, the z-score is a useful tool in statistical analysis that helps researchers and analysts make sense of data and draw meaningful conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d42a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348901eb",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) states that if we take a large number of independent and identically distributed random variables and calculate their sample mean or sum, then the distribution of these sample statistics will approximate a normal distribution, regardless of the shape of the underlying population distribution. This means that as the sample size increases, the distribution of the sample mean or sum will become more and more normal.\n",
    "\n",
    "Let's take an example to understand the concept of the CLT in detail. Suppose we want to know the average height of all the students in a particular school. We can take a random sample of, say, 50 students, and calculate their average height. We repeat this process multiple times and obtain the sample means of different samples.\n",
    "\n",
    "The distribution of these sample means will follow the CLT, which states that the distribution will be approximately normal, regardless of the shape of the population distribution. For example, if the population distribution of student heights is skewed, the distribution of the sample means will still be normal.\n",
    "\n",
    "\n",
    "The significance of the CLT is that it provides a powerful tool for statistical inference, especially in situations where the underlying distribution of the data is unknown or non-normal. It allows us to use the normal distribution as an approximation for the distribution of sample means or sample sums, which is often much easier to work with mathematically.\n",
    "The CLT is also important in hypothesis testing, where we use sample means to test hypotheses about population means. In many cases, the CLT allows us to use the normal distribution to make inferences about the population mean even when the sample size is relatively small, provided that the underlying population is approximately normal or the sample size is large enough.\n",
    "\n",
    "Overall, the CLT is a fundamental concept in statistics that underpins much of modern statistical theory and practice, and is widely used in fields such as economics, finance, engineering, and social sciences, among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447d766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033de2c6",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a statistical theorem that states that the sampling distribution of the mean of any independent, identically distributed random variables approaches a normal distribution as the sample size increases. The assumptions of the CLT are as follows:\n",
    "\n",
    "1) Random sampling: The samples are drawn randomly from the population.\n",
    "\n",
    "2) Sample size: The sample size is sufficiently large. There is no consensus on how large is \"sufficient,\" but generally, the sample size should be at least 30.\n",
    "\n",
    "3) Independence: The observations in the sample must be independent of one another. This means that the value of one observation should not be influenced by the value of any other observation in the sample.\n",
    "\n",
    "4) Finite variance: The population from which the sample is drawn must have a finite variance. This assumption is necessary to ensure that the sample mean has a well-defined variance as the sample size approaches infinity.\n",
    "\n",
    "If these assumptions are satisfied, then the distribution of sample means will be approximately normal, regardless of the underlying distribution of the population from which the sample is drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bfd60b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
